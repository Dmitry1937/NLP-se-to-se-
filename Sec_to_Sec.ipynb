{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sec_to_Sec.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNHr0/M5N+9chqn+ERy+Mc0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dmitry1937/NLP-se-to-se-/blob/main/Sec_to_Sec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM1ERlA0a8AG"
      },
      "source": [
        "  ## Подгтовка DF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7apqi661xXb",
        "outputId": "3f648415-d63d-4641-c69e-b6ad46ab6390"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ltEK0kA2MzD",
        "outputId": "028b1e41-08c7-468e-8a22-9384e2466dd4"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/Skillbox/ChatBot_Dataset.zip -d ChatBot_Dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Skillbox/ChatBot_Dataset.zip\n",
            "replace ChatBot_Dataset/SOURCE.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JU67IPY3s_0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-aluM2iffYk"
      },
      "source": [
        "#raw_script_urls = pd.read_csv('ChatBot_Dataset/raw_script_urls.txt', sep = ' \\+\\+\\+\\$\\+\\+\\+ ',header=None, engine='python'  ) \n",
        "#raw_script_urls.head()\n",
        "#movie_titles_metadata = pd.read_csv('ChatBot_Dataset/movie_titles_metadata.txt', sep = ' \\+\\+\\+\\$\\+\\+\\+ ',header=None, engine='python'  ) \n",
        "#movie_titles_metadata.head()\n",
        "#movie_characters_metadata = pd.read_csv('ChatBot_Dataset/movie_characters_metadata.txt', sep = ' \\+\\+\\+\\$\\+\\+\\+ ',header=None, engine='python'  ) \n",
        "#movie_characters_metadata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2_N-Nf40e7bU",
        "outputId": "30b22d54-b862-4706-811c-5ec7daff19c4"
      },
      "source": [
        "#read movie_conversations.txt\n",
        "movie_conversations = pd.read_csv('ChatBot_Dataset/movie_conversations.txt', sep = ' \\+\\+\\+\\$\\+\\+\\+ ',header=None, engine='python' ,parse_dates=True ) \n",
        "movie_conversations.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L194', 'L195', 'L196', 'L197']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L198', 'L199']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L200', 'L201', 'L202', 'L203']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L204', 'L205', 'L206']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L207', 'L208']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0   1   2                                 3\n",
              "0  u0  u2  m0  ['L194', 'L195', 'L196', 'L197']\n",
              "1  u0  u2  m0                  ['L198', 'L199']\n",
              "2  u0  u2  m0  ['L200', 'L201', 'L202', 'L203']\n",
              "3  u0  u2  m0          ['L204', 'L205', 'L206']\n",
              "4  u0  u2  m0                  ['L207', 'L208']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epYW7urDCRHW"
      },
      "source": [
        "def parser (srtings):\n",
        "  #Функция превращает текст в список с индексами строчек\n",
        "  new = []\n",
        "  number =''\n",
        "  for c in srtings[2:-2]:\n",
        "    if not (c in '\\', '):\n",
        "      number +=c\n",
        "    elif number != '' :\n",
        "      new.append(number)\n",
        "      number = ''\n",
        "  new.append(number)\n",
        "  return new\n",
        "\n",
        "\n",
        "def set_pair (dialogs:str) : \n",
        "    #Функция создает все возможные пары для диалогов с одной строчки\n",
        "    set_pairs = list()\n",
        "    dialogs = parser (dialogs)\n",
        "    n_old = dialogs[0]\n",
        "    for n in dialogs[1:]:\n",
        "      set_pairs.append([n_old,n])\n",
        "      n_old = n\n",
        "      \n",
        "    return set_pairs\n",
        "\n",
        "\n",
        "def all_pair (col):\n",
        "  #Функция создает список всех возможных пар в предложенном сете\n",
        "  all_pairs = []\n",
        "  for c in col:\n",
        "    for n in c:\n",
        "\n",
        "      all_pairs.append(n)\n",
        "  \n",
        "  return all_pairs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "GMWmpRnxO9uX",
        "outputId": "0541d073-e069-4078-ac54-d77131de925c"
      },
      "source": [
        "#С помощью функций созданных выше формируем DataFrame со всеми парами\n",
        "all_pairs = movie_conversations.agg({3 : set_pair })\n",
        "all_pairs = pd.DataFrame(all_pairs.aggregate(all_pair, axis =0, ).values.squeeze().tolist() , columns=['s','f'])\n",
        "all_pairs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s</th>\n",
              "      <th>f</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L194</td>\n",
              "      <td>L195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L195</td>\n",
              "      <td>L196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L196</td>\n",
              "      <td>L197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>L198</td>\n",
              "      <td>L199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L200</td>\n",
              "      <td>L201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221611</th>\n",
              "      <td>L666369</td>\n",
              "      <td>L666370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221612</th>\n",
              "      <td>L666370</td>\n",
              "      <td>L666371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221613</th>\n",
              "      <td>L666371</td>\n",
              "      <td>L666372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221614</th>\n",
              "      <td>L666520</td>\n",
              "      <td>L666521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221615</th>\n",
              "      <td>L666521</td>\n",
              "      <td>L666522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>221616 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              s        f\n",
              "0          L194     L195\n",
              "1          L195     L196\n",
              "2          L196     L197\n",
              "3          L198     L199\n",
              "4          L200     L201\n",
              "...         ...      ...\n",
              "221611  L666369  L666370\n",
              "221612  L666370  L666371\n",
              "221613  L666371  L666372\n",
              "221614  L666520  L666521\n",
              "221615  L666521  L666522\n",
              "\n",
              "[221616 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "oUPYOp4JOsgX",
        "outputId": "b14c3125-bd57-46a8-ae36-35b25f6fc1a7"
      },
      "source": [
        "#read movie_lines.txt\n",
        "colums = ['0','1','2','3','4',]\n",
        "movie_lines = pd.read_csv('ChatBot_Dataset/movie_lines.txt', sep = ' \\+\\+\\+\\$\\+\\+\\+ ',header=None, engine='python' , ) \n",
        "movie_lines.columns = colums\n",
        "movie_lines.dropna(inplace=True)\n",
        "movie_lines.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L1045</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>They do not!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L1044</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>They do to!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L985</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>I hope so.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>L984</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>She okay?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L925</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>Let's go.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0   1   2        3             4\n",
              "0  L1045  u0  m0   BIANCA  They do not!\n",
              "1  L1044  u2  m0  CAMERON   They do to!\n",
              "2   L985  u0  m0   BIANCA    I hope so.\n",
              "3   L984  u2  m0  CAMERON     She okay?\n",
              "4   L925  u0  m0   BIANCA     Let's go."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DVlfNmPxgGC8",
        "outputId": "bd69fbc3-ea7f-4b4c-8ae0-61198f2fbebb"
      },
      "source": [
        "#Создаем DataFrame для работы\n",
        "df = all_pairs.merge(movie_lines[['0','4']],left_on='s', right_on='0',  )\n",
        "df = df.merge(movie_lines[['0','4']],left_on='f', right_on='0',)\n",
        "df.drop(['s', 'f','0_x','0_y'], axis=1,inplace=True)\n",
        "df.columns = ['start','finish']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>finish</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
              "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
              "      <td>Not the hacking and gagging and spitting part....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not the hacking and gagging and spitting part....</td>\n",
              "      <td>Okay... then how 'bout we try out some French ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
              "      <td>Forget it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
              "      <td>Cameron.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               start                                             finish\n",
              "0  Can we make this quick?  Roxanne Korrine and A...  Well, I thought we'd start with pronunciation,...\n",
              "1  Well, I thought we'd start with pronunciation,...  Not the hacking and gagging and spitting part....\n",
              "2  Not the hacking and gagging and spitting part....  Okay... then how 'bout we try out some French ...\n",
              "3  You're asking me out.  That's so cute. What's ...                                         Forget it.\n",
              "4  No, no, it's my fault -- we didn't have a prop...                                           Cameron."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzaJnqo9a30y"
      },
      "source": [
        "### Подготовим текс к ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh97PsNJbO-1"
      },
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import tensorflow as tf\n",
        "'''import attention \n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import class_weight'''\n",
        "from keras import initializers, regularizers, constraints\n",
        "\n",
        "\n",
        "#nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN0JDX6aw3EX"
      },
      "source": [
        "def plus_words (text):\n",
        "  return '11star11 '+text+' 11finish11'\n",
        "df = df.apply(plus_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX6LBCfiygnw",
        "outputId": "4a7b1bae-1ce0-4d5f-cf8a-f1ed61f355ec"
      },
      "source": [
        "# prepare tokenizer\n",
        "t = Tokenizer( )\n",
        "t.fit_on_texts(df.start\t +' '+ df.finish)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55748"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js_jU4Eqgtu6"
      },
      "source": [
        "# integer encode the documents\n",
        "encoded_docs_start = t.texts_to_sequences(df.start, )\n",
        "encoded_docs_finish = t.texts_to_sequences(df.finish, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbjX4ZlagTKZ",
        "outputId": "6792862e-a2b3-4bee-f023-474f61af3ef9"
      },
      "source": [
        "max_length = 0\n",
        "for i in encoded_docs_start:\n",
        "  max_length +=len(i)\n",
        "max_length = int(max_length/len(encoded_docs_start))\n",
        "max_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFek1iyih7zy",
        "outputId": "8a8cfe57-514f-4c35-9bd0-e532890fbcbd"
      },
      "source": [
        "MAX_LEN = 7 # Для чат бота 5 слов + старт стоп\n",
        "MAX_LEN "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9easYXBOjKsu"
      },
      "source": [
        "too_long = []\n",
        "for indx,i in enumerate(encoded_docs_start):\n",
        "  if len(i)>MAX_LEN:\n",
        "    too_long.append(indx)\n",
        "len(too_long)\n",
        "\n",
        "for indx,i in enumerate(encoded_docs_finish):\n",
        "  if len(i)>MAX_LEN:\n",
        "    too_long.append(indx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ulg_cpjJkyAE",
        "outputId": "ba8b7bd2-22a5-40d8-c4db-e1d2add7c852"
      },
      "source": [
        "# Что бы не путать сеть с незаконченными фразами принято решения удолить пары где более 20 слов на start или finish\n",
        "too_long = set(too_long)\n",
        "df = df.drop(index=too_long,axis=0 ,).reset_index()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>start</th>\n",
              "      <th>finish</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15</td>\n",
              "      <td>11star11 There. 11finish11</td>\n",
              "      <td>11star11 Where? 11finish11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26</td>\n",
              "      <td>11star11 Have fun tonight? 11finish11</td>\n",
              "      <td>11star11 Tons 11finish11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31</td>\n",
              "      <td>11star11 But 11finish11</td>\n",
              "      <td>11star11 You always been this selfish? 11finish11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>11star11 What good stuff? 11finish11</td>\n",
              "      <td>11star11 The \"real you\". 11finish11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>11star11 Wow 11finish11</td>\n",
              "      <td>11star11 Let's go. 11finish11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39143</th>\n",
              "      <td>221181</td>\n",
              "      <td>11star11 Yes, sir, name, please? 11finish11</td>\n",
              "      <td>11star11 Food! 11finish11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39144</th>\n",
              "      <td>221182</td>\n",
              "      <td>11star11 Food! 11finish11</td>\n",
              "      <td>11star11 Do you have a reservation? 11finish11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39145</th>\n",
              "      <td>221183</td>\n",
              "      <td>11star11 Do you have a reservation? 11finish11</td>\n",
              "      <td>11star11 Food!! 11finish11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39146</th>\n",
              "      <td>221188</td>\n",
              "      <td>11star11 GRRRHMMNNNJKJMMMNN! 11finish11</td>\n",
              "      <td>11star11 Franz!  Help!  Lunatic! 11finish11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39147</th>\n",
              "      <td>221222</td>\n",
              "      <td>11star11 Stuart? 11finish11</td>\n",
              "      <td>11star11 Yes. 11finish11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39148 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        index  ...                                             finish\n",
              "0          15  ...                         11star11 Where? 11finish11\n",
              "1          26  ...                           11star11 Tons 11finish11\n",
              "2          31  ...  11star11 You always been this selfish? 11finish11\n",
              "3          37  ...                11star11 The \"real you\". 11finish11\n",
              "4          41  ...                      11star11 Let's go. 11finish11\n",
              "...       ...  ...                                                ...\n",
              "39143  221181  ...                          11star11 Food! 11finish11\n",
              "39144  221182  ...     11star11 Do you have a reservation? 11finish11\n",
              "39145  221183  ...                         11star11 Food!! 11finish11\n",
              "39146  221188  ...        11star11 Franz!  Help!  Lunatic! 11finish11\n",
              "39147  221222  ...                           11star11 Yes. 11finish11\n",
              "\n",
              "[39148 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw5KfQ6_yWu_",
        "outputId": "b6026ebf-80de-4fb0-cecf-7511de181607"
      },
      "source": [
        "#Повторим операцию с подготовленным df\n",
        "t = Tokenizer( )\n",
        "t.fit_on_texts(df.start\t +' '+ df.finish)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13610"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAEoXppimU4d"
      },
      "source": [
        "# integer encode the documents\n",
        "encoded_docs_start = t.texts_to_sequences(df.start, )\n",
        "encoded_docs_finish = t.texts_to_sequences(df.finish, )\n",
        "\n",
        "padded_docs_start = pad_sequences(encoded_docs_start, maxlen=MAX_LEN, padding='post', )\n",
        "padded_docs_finish  = pad_sequences(encoded_docs_finish, maxlen=MAX_LEN+1, padding='post', )\n",
        "\n",
        "encoded_docs_finish_input = np.array([i[:-1] for i in padded_docs_finish])\n",
        "encoded_docs_finish_target = np.array([i[1:] for i in padded_docs_finish])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw58tWcenFfD",
        "outputId": "350f6233-d93c-45b7-f297-126511c002c1"
      },
      "source": [
        "#Проверка\n",
        "max_length = 0\n",
        "for i in encoded_docs_start:\n",
        "  if max_length< len(i):\n",
        "    max_length =  len(i)\n",
        "print(max_length)\n",
        "\n",
        "\n",
        "max_length = 0\n",
        "for i in encoded_docs_finish:\n",
        "  if max_length< len(i):\n",
        "    max_length =  len(i)\n",
        "print(max_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpwL8XAYrata",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "99b52d49-2cea-424a-fa25-0a514abaf660"
      },
      "source": [
        "'''# pad documents to a max length of words\n",
        "padded_docs_start = pad_sequences(encoded_docs_start, maxlen=MAX_LEN, padding='post', )\n",
        "padded_docs_finish_input  = pad_sequences(encoded_docs_finish_input, maxlen=MAX_LEN, padding='post', )\n",
        "padded_docs_finish_target  = pad_sequences(encoded_docs_finish_target, maxlen=MAX_LEN, padding='post', )'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"# pad documents to a max length of words\\npadded_docs_start = pad_sequences(encoded_docs_start, maxlen=MAX_LEN, padding='post', )\\npadded_docs_finish_input  = pad_sequences(encoded_docs_finish_input, maxlen=MAX_LEN, padding='post', )\\npadded_docs_finish_target  = pad_sequences(encoded_docs_finish_target, maxlen=MAX_LEN, padding='post', )\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDG3U8ZyoizQ"
      },
      "source": [
        "MAX_SEQ_LEN = MAX_LEN #1000\n",
        "EMB_SIZE = 50 # Размер векторного представления (эмбеддинга)\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM-3x7eIqN7w"
      },
      "source": [
        "### GloVE как  Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pb_R6y-qDEu",
        "outputId": "2deeefaf-27b7-47ae-cb0f-6aac0fe1cf6f"
      },
      "source": [
        "import os, requests, shutil\n",
        "\n",
        "glove_dir = './data/RNN/'\n",
        "glove_100k_50d = 'glove.first-100k.6B.50d.txt'\n",
        "glove_100k_50d_path = os.path.join(glove_dir, glove_100k_50d)\n",
        "\n",
        "# These are temporary files if we need to download it from the original source (slow)\n",
        "#The original file is at http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "data_cache = './data/cache'\n",
        "glove_full_tar = 'glove.6B.zip'\n",
        "glove_full_50d = 'glove.6B.50d.txt'\n",
        "\n",
        "#force_download_from_original=False\n",
        "download_url= 'http://redcatlabs.com/downloads/deep-learning-workshop/notebooks/data/RNN/'+glove_100k_50d\n",
        "original_url = 'http://nlp.stanford.edu/data/'+glove_full_tar\n",
        "\n",
        "if not os.path.isfile( glove_100k_50d_path ):\n",
        "    if not os.path.exists(glove_dir):\n",
        "        os.makedirs(glove_dir)\n",
        "    \n",
        "    # First, try to download a pre-prepared file directly...\n",
        "    response = requests.get(download_url, stream=True)\n",
        "    if response.status_code == requests.codes.ok:\n",
        "        print(\"Downloading 42Mb pre-prepared GloVE file from RedCatLabs\")\n",
        "        with open(glove_100k_50d_path, 'wb') as out_file:\n",
        "            shutil.copyfileobj(response.raw, out_file)\n",
        "    else:\n",
        "        # But, for some reason, RedCatLabs didn't give us the file directly\n",
        "        if not os.path.exists(data_cache):\n",
        "            os.makedirs(data_cache)\n",
        "        \n",
        "        if not os.path.isfile( os.path.join(data_cache, glove_full_50d) ):\n",
        "            zipfilepath = os.path.join(data_cache, glove_full_tar)\n",
        "            if not os.path.isfile( zipfilepath ):\n",
        "                print(\"Downloading 860Mb GloVE file from Stanford\")\n",
        "                response = requests.get(download_url, stream=True)\n",
        "                with open(zipfilepath, 'wb') as out_file:\n",
        "                    shutil.copyfileobj(response.raw, out_file)\n",
        "            if os.path.isfile(zipfilepath):\n",
        "                print(\"Unpacking 50d GloVE file from zip\")\n",
        "                import zipfile\n",
        "                zipfile.ZipFile(zipfilepath, 'r').extract(glove_full_50d, data_cache)\n",
        "\n",
        "        with open(os.path.join(data_cache, glove_full_50d), 'rt') as in_file:\n",
        "            with open(glove_100k_50d_path, 'wt') as out_file:\n",
        "                print(\"Reducing 50d GloVE file to first 100k words\")\n",
        "                for i, l in enumerate(in_file.readlines()):\n",
        "                    if i>=100000: break\n",
        "                    out_file.write(l)\n",
        "    \n",
        "        # Get rid of tarfile source (the required text file itself will remain)\n",
        "        #os.unlink(zipfilepath)\n",
        "        #os.unlink(os.path.join(data_cache, glove_full_50d))\n",
        "\n",
        "print(\"GloVE available locally\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GloVE available locally\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlRi64HYqGxp"
      },
      "source": [
        "filename = 'data/RNN/glove.first-100k.6B.50d.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3NIsHeym6ol",
        "outputId": "8abec8ac-da6f-4501-ac9d-2b2e7b48a1a0"
      },
      "source": [
        "#encoded_docs_finish_input = [i[:-1] for i in padded_docs_finish]\n",
        "#encoded_docs_finish_target = [i[1:] for i in padded_docs_finish]\n",
        "len(encoded_docs_finish_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39148"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe6D8M-eq24H"
      },
      "source": [
        "# split the data into a training set and a validation set\n",
        "VALIDATION_SPLIT = 0.2\n",
        "indices = np.arange(padded_docs_start.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "padded_docs_start = padded_docs_start[indices]\n",
        "encoded_docs_finish_input = encoded_docs_finish_input[indices]\n",
        "encoded_docs_finish_target = encoded_docs_finish_target[indices]\n",
        "\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * padded_docs_start.shape[0])\n",
        "\n",
        "x_train = padded_docs_start[:-nb_validation_samples]\n",
        "y_train_input = encoded_docs_finish_input[:-nb_validation_samples]\n",
        "y_train_target = encoded_docs_finish_target[:-nb_validation_samples]\n",
        "x_val = padded_docs_start[-nb_validation_samples:]\n",
        "y_val_input = encoded_docs_finish_input[-nb_validation_samples:]\n",
        "y_val_target = encoded_docs_finish_target[-nb_validation_samples:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDI3CXlGrSzp",
        "outputId": "936606cb-cdf1-4411-f954-425120422e45"
      },
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open(filename)\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.array(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 100000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_unC-YXsEN2"
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "EMB_SIZE = 50 # размерность эмбеддингов (и для входных и для выходных цепочек)\n",
        "embedding_matrix = np.zeros((vocab_size, EMB_SIZE))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector\n",
        "embedding_matrix[t.word_index['11star11']] = np.zeros(50)\n",
        "embedding_matrix[t.word_index['11finish11']] = np.ones(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE8c2zVsTLUK"
      },
      "source": [
        "from keras.layers import Activation, dot, concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1ePMJTe1RKe"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkIlvkhFsrhu"
      },
      "source": [
        "H_SIZE = 512 # Размерность скрытого состояния LSTM\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(vocab_size, EMB_SIZE,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_length,\n",
        "                            trainable=False\n",
        "                                               )\n",
        "        self.lstm1 = tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True, dropout=0.05)\n",
        "        self.lstm2 = tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True, dropout=0.05)\n",
        "\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embed(x)\n",
        "        out, h, c, = self.lstm1(out)\n",
        "        state  = self.lstm2(out)\n",
        "        \n",
        "        return state\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(vocab_size, EMB_SIZE,weights=[embedding_matrix],\n",
        "                            input_length=max_length,\n",
        "                            trainable=False\n",
        "                                               )\n",
        "        self.lstm = tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True,dropout=0.05)\n",
        "        self.attention = tf.keras.layers.Dense(max_length, activation='softmax')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "        \n",
        "    def call(self, x, init_state):\n",
        "        out = self.embed(x)\n",
        "        \n",
        "        out, h, c = self.lstm(out, initial_state=(init_state[1:]),)\n",
        "\n",
        "        atten = dot([out, init_state[0]], axes=[2, 2])\n",
        "        attention = Activation('softmax', name='attention')(atten)\n",
        "        context = dot([attention, init_state[0]], axes=[2,1])\n",
        "\n",
        "        decoder_combined_context = concatenate([context, out])\n",
        "\n",
        "        out = self.fc(decoder_combined_context)\n",
        "        state = (h, c)\n",
        "        return out, state\n",
        "\n",
        "encoder_model = Encoder()\n",
        "decoder_model = Decoder()\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "enc_state = encoder_model(encoder_inputs)\n",
        "decoder_outputs, _ = decoder_model(decoder_inputs, enc_state)\n",
        "\n",
        "seq2seq = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va7oqysCtDRJ",
        "outputId": "d11d71ea-5fb5-4d26-809f-3ed9947ae83b"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "EPOCHS = 45\n",
        "\n",
        "loss = tf.losses.SparseCategoricalCrossentropy()\n",
        "seq2seq.compile(optimizer='nadam', loss=loss, metrics=['accuracy'])\n",
        "seq2seq.fit([x_train, y_train_input], y_train_target, \n",
        "          batch_size=BATCH_SIZE, \n",
        "          epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/45\n",
            "123/123 [==============================] - 14s 73ms/step - loss: 4.1029 - accuracy: 0.5037\n",
            "Epoch 2/45\n",
            "123/123 [==============================] - 9s 73ms/step - loss: 2.8930 - accuracy: 0.5861\n",
            "Epoch 3/45\n",
            "123/123 [==============================] - 9s 73ms/step - loss: 2.7985 - accuracy: 0.5897\n",
            "Epoch 4/45\n",
            "123/123 [==============================] - 9s 73ms/step - loss: 2.7030 - accuracy: 0.5937\n",
            "Epoch 5/45\n",
            "123/123 [==============================] - 9s 73ms/step - loss: 2.6361 - accuracy: 0.5925\n",
            "Epoch 6/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 2.5489 - accuracy: 0.5958\n",
            "Epoch 7/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 2.4687 - accuracy: 0.5973\n",
            "Epoch 8/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 2.3845 - accuracy: 0.6000\n",
            "Epoch 9/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 2.3044 - accuracy: 0.6021\n",
            "Epoch 10/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 2.2172 - accuracy: 0.6058\n",
            "Epoch 11/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 2.1396 - accuracy: 0.6100\n",
            "Epoch 12/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 2.0518 - accuracy: 0.6184\n",
            "Epoch 13/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.9734 - accuracy: 0.6256\n",
            "Epoch 14/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.8994 - accuracy: 0.6334\n",
            "Epoch 15/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.8244 - accuracy: 0.6405\n",
            "Epoch 16/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.7486 - accuracy: 0.6487\n",
            "Epoch 17/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.6704 - accuracy: 0.6591\n",
            "Epoch 18/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.6091 - accuracy: 0.6654\n",
            "Epoch 19/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.5433 - accuracy: 0.6747\n",
            "Epoch 20/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.4849 - accuracy: 0.6823\n",
            "Epoch 21/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.4181 - accuracy: 0.6937\n",
            "Epoch 22/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.3581 - accuracy: 0.7027\n",
            "Epoch 23/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.3070 - accuracy: 0.7111\n",
            "Epoch 24/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.2547 - accuracy: 0.7211\n",
            "Epoch 25/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.1916 - accuracy: 0.7324\n",
            "Epoch 26/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.1352 - accuracy: 0.7429\n",
            "Epoch 27/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.0856 - accuracy: 0.7522\n",
            "Epoch 28/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 1.0352 - accuracy: 0.7633\n",
            "Epoch 29/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.9876 - accuracy: 0.7728\n",
            "Epoch 30/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.9489 - accuracy: 0.7820\n",
            "Epoch 31/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.8973 - accuracy: 0.7930\n",
            "Epoch 32/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.8568 - accuracy: 0.8025\n",
            "Epoch 33/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.8138 - accuracy: 0.8113\n",
            "Epoch 34/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.7694 - accuracy: 0.8223\n",
            "Epoch 35/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.7313 - accuracy: 0.8317\n",
            "Epoch 36/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.6939 - accuracy: 0.8408\n",
            "Epoch 37/45\n",
            "123/123 [==============================] - 9s 73ms/step - loss: 0.6628 - accuracy: 0.8475\n",
            "Epoch 38/45\n",
            "123/123 [==============================] - 9s 73ms/step - loss: 0.6258 - accuracy: 0.8568\n",
            "Epoch 39/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.6016 - accuracy: 0.8616\n",
            "Epoch 40/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.5677 - accuracy: 0.8697\n",
            "Epoch 41/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.5363 - accuracy: 0.8773\n",
            "Epoch 42/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.5162 - accuracy: 0.8822\n",
            "Epoch 43/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.4902 - accuracy: 0.8878\n",
            "Epoch 44/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.4750 - accuracy: 0.8907\n",
            "Epoch 45/45\n",
            "123/123 [==============================] - 9s 72ms/step - loss: 0.4506 - accuracy: 0.8965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbcb132c828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE5H9U7D45Dg"
      },
      "source": [
        "def seq2seq_inference(input_seq):\n",
        "    state = encoder_model(input_seq)\n",
        "    target_seq = np.array([[1]])\n",
        "    out = state[0]\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while True:\n",
        "        output_tokens,state = decoder_model(target_seq, state)\n",
        "        \n",
        "        state = out,*state\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        if sampled_token_index>0 :\n",
        "          sampled_char = t.index_word[sampled_token_index]\n",
        "        else :\n",
        "          sampled_char = 'post'\n",
        "\n",
        "        #decoded_sentence += sampled_char +' '\n",
        "        if (sampled_char == '11finish11' or\n",
        "           len(decoded_sentence) > MAX_LEN):\n",
        "            #print(decoded_sentence)\n",
        "            break\n",
        "        decoded_sentence += sampled_char +' '\n",
        "\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZbyTFHN5Vjb",
        "outputId": "14f49b29-7ff3-43a0-a427-86b0df9e2905"
      },
      "source": [
        "for seq_index in indices[-15:-20:-1]:\n",
        "    input_seq = padded_docs_start[seq_index: seq_index + 1]\n",
        "    decoded_sentence = seq2seq_inference(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', df.start[indices].iloc[seq_index].split('11finish11')[0][8:])\n",
        "    print('Result sentence:', decoded_sentence)\n",
        "    print('Target sentence:', df.finish[indices].iloc[seq_index].split('11finish11')[0][8:])\n",
        "    print('-')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence:  Yes. \n",
            "Result sentence: you personally \n",
            "Target sentence:  Why? \n",
            "-\n",
            "-\n",
            "Input sentence:  About tonsils. \n",
            "Result sentence: u tonsili \n",
            "Target sentence:  <u>Tonsili!</u> \n",
            "-\n",
            "-\n",
            "Input sentence:  Very well, m'sieu. \n",
            "Result sentence: otherwise \n",
            "Target sentence:  Otherwise I'll call the police \n",
            "-\n",
            "-\n",
            "Input sentence:  David? \n",
            "Result sentence: ellie \n",
            "Target sentence:  Who's there? \n",
            "-\n",
            "-\n",
            "Input sentence:  You're shaking. \n",
            "Result sentence: i don't \n",
            "Target sentence:  It's the tension. \n",
            "-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytmTmQRQEcH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "248ca2a2-7fc4-4311-ee39-3e2518c01b39"
      },
      "source": [
        "for seq_index in indices[-25:-40:-1]:\n",
        "    input_seq = padded_docs_start[seq_index: seq_index + 1]\n",
        "    decoded_sentence = seq2seq_inference(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', df.start[indices].iloc[seq_index].split('11finish11')[0][8:])\n",
        "    print('Result sentence:', decoded_sentence)\n",
        "    print('Target sentence:', df.finish[indices].iloc[seq_index].split('11finish11')[0][8:])\n",
        "    print('-')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence:  Syevodnya? \n",
            "Result sentence: what \n",
            "Target sentence:  Syevodnya \n",
            "-\n",
            "-\n",
            "Input sentence:  That's me. \n",
            "Result sentence: i'm glad \n",
            "Target sentence:  No it is not! \n",
            "-\n",
            "-\n",
            "Input sentence:  Can't you see? \n",
            "Result sentence: father of \n",
            "Target sentence:  Oh, yeah. There. \n",
            "-\n",
            "-\n",
            "Input sentence:  A hotel? \n",
            "Result sentence: it's a loft \n",
            "Target sentence:  It's not used for anything. \n",
            "-\n",
            "-\n",
            "Input sentence:  Murphy to Epps. \n",
            "Result sentence: epps \n",
            "Target sentence:  Epps. \n",
            "-\n",
            "-\n",
            "Input sentence:  What about Miss Lawson? \n",
            "Result sentence: yes cocaine \n",
            "Target sentence:  Yes -- cocaine. \n",
            "-\n",
            "-\n",
            "Input sentence:  Not these guys. \n",
            "Result sentence: yeah those \n",
            "Target sentence:  Yeah, those guys too. \n",
            "-\n",
            "-\n",
            "Input sentence:  Yes. \n",
            "Result sentence: you personally \n",
            "Target sentence:  No further questions. \n",
            "-\n",
            "-\n",
            "Input sentence:  It's the game, ARCADE. \n",
            "Result sentence: you don't \n",
            "Target sentence:  You don't like it? \n",
            "-\n",
            "-\n",
            "Input sentence:  Who's next, Mrs. Rabinow. \n",
            "Result sentence: her \n",
            "Target sentence:  We rest, Your Honor. \n",
            "-\n",
            "-\n",
            "Input sentence:  The hats. \n",
            "Result sentence: yes \n",
            "Target sentence:  A beret. \n",
            "-\n",
            "-\n",
            "Input sentence:  There's nothing harder. \n",
            "Result sentence: what about \n",
            "Target sentence:  Snuff? \n",
            "-\n",
            "-\n",
            "Input sentence:  Yes! \n",
            "Result sentence: you personally \n",
            "Target sentence:  The master ... is asleep! \n",
            "-\n",
            "-\n",
            "Input sentence:  How old are you? \n",
            "Result sentence: twenty five \n",
            "Target sentence:  That's no secret. I'm five. \n",
            "-\n",
            "-\n",
            "Input sentence:  Yes, I am. \n",
            "Result sentence: plastics \n",
            "Target sentence:  No, you're not. \n",
            "-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CofIVEs1XqP"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-boe4Kbz667"
      },
      "source": [
        "Проверять на таких данных не совсем корректно, так как есть leak (связанная с тем что данные  начало диалога которые val могут быть в train df как конец диалога и наоборот. Но тем не менее несмотря на отсутствия контекста иногда получается достаточно осмысленной ответ. Я изначально упростил задачу исключив длинные предложения, так как это бы значительно увеличило вектор ответов. В чем нет необходимости для Chat bota"
      ]
    }
  ]
}